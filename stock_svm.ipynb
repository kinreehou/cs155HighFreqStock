{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.svm import SVR\n",
    "import numpy as np\n",
    "import csv\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import scipy\n",
    "from scipy.stats.stats import pearsonr\n",
    "from scipy import stats\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y=1 112467722.6\n",
      "X test [0.71322034 0.71225457 0.06669445 0.0892853  0.         0.58333333\n",
      " 0.71225457 0.71225457 0.71370421 0.71370421 0.71370421 0.71225457\n",
      " 0.71205962 0.71186441 0.71254237 0.71254237 0.04878049 0.1025641\n",
      " 0.01886792 0.         0.02739726 0.         0.05263158 0.\n",
      " 0.02020202 0.01204819 0.         0.04964193 0.10894998 0.02088447\n",
      " 0.00145456 0.02917758 0.00158062 0.05568534 0.00099343 0.0215059 ]\n",
      "=============================\n",
      "1 0.001\n",
      "[15624.9601327  15625.16665253 15625.02835104 ... 15624.99392718\n",
      " 15625.21698274 15625.66042707]\n",
      "-15403.74110426831\n",
      "[15625.09834639 15625.09834639 15625.09834639 15625.09834639\n",
      " 15625.09834639 15625.09834639 15625.09834639 15625.09834639\n",
      " 15625.09834639 15625.09834639 15625.09834639 15625.09834639\n",
      " 15625.09834639 15625.09834639 15625.09834639 15625.09834639\n",
      " 15625.09834639 15625.09834639 15625.09834639 15625.09834639\n",
      " 15625.09834639 15625.09834639 15625.09834639 15625.09834639\n",
      " 15625.09834639 15625.09834639 15625.09834639 15625.09834639\n",
      " 15625.09834639]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "all_data=pd.read_csv('./data/train.csv')\n",
    "##replace NaN with column mean\n",
    "all_data.fillna(all_data.mean(),inplace = True) \n",
    "\n",
    "#df = all_data.drop([\"id\",\"opened_position_qty \" ,\"closed_position_qty\" ,\"transacted_qty\",\"d_open_interest\",\"bid1\",\"bid2\",\"bid3\",\"bid4\",\"bid5\",\"ask1\",\"ask2\",\"ask3\",\"ask4\",\"ask5\"],axis=1)\n",
    "all_data[\"bid1sum\"]=all_data[\"bid1\"]*all_data[\"bid1vol\"]\n",
    "all_data[\"bid2sum\"]=all_data[\"bid2\"]*all_data[\"bid2vol\"]\n",
    "all_data[\"bid3sum\"]=all_data[\"bid3\"]*all_data[\"bid3vol\"]\n",
    "all_data[\"bid4sum\"]=all_data[\"bid4\"]*all_data[\"bid4vol\"]\n",
    "all_data[\"bid5sum\"]=all_data[\"bid5\"]*all_data[\"bid5vol\"]\n",
    "all_data[\"ask1sum\"]=all_data[\"ask1\"]*all_data[\"ask1vol\"]\n",
    "all_data[\"ask2sum\"]=all_data[\"ask2\"]*all_data[\"ask2vol\"]\n",
    "all_data[\"ask3sum\"]=all_data[\"ask3\"]*all_data[\"ask3vol\"]\n",
    "all_data[\"ask4sum\"]=all_data[\"ask4\"]*all_data[\"ask4vol\"]\n",
    "all_data[\"ask5sum\"]=all_data[\"ask5\"]*all_data[\"ask5vol\"]\n",
    "\n",
    "\n",
    "##downsizing for test\n",
    "all_data=all_data.sample(frac=0.01, random_state=1)\n",
    "\n",
    "train_dataset = all_data.sample(frac=0.8, random_state=1)\n",
    "test_dataset = all_data.drop(train_dataset.index)\n",
    "\n",
    "Train = train_dataset.to_numpy()\n",
    "Test = test_dataset.to_numpy()\n",
    "    \n",
    "X_train = Train[:,1:-1]\n",
    "Y_train = Train[:,-1]\n",
    "print('y=1', np.sum(Y_train, axis=0))\n",
    "\n",
    "X_test = Test[:,1:-1]\n",
    "Y_test = Test[:,-1]\n",
    "\n",
    "\n",
    "# Applying feature scaling on the train data  \n",
    "min_max_scaler = MinMaxScaler()\n",
    "X_test = min_max_scaler.fit_transform(X_test)\n",
    "X_train = min_max_scaler.fit_transform(X_train)\n",
    "print('X test',X_test[1])\n",
    "\n",
    "C_vals=[1,10,1e2,1e3,1e4,1e5]\n",
    "gamma_vals=[1e-12, 1e-9, 1e-6, 1e-3, 1,1e2]\n",
    "for i in range(1):\n",
    "    for j in range(1):\n",
    "        #C_val=C_vals[i]\n",
    "        C_val=1\n",
    "        #gamma_val=gamma_vals[j]\n",
    "        gamma_val=0.001\n",
    "        print('=============================')\n",
    "        print(C_val,gamma_val)\n",
    "\n",
    "        classifier = SVR(kernel = 'rbf', C=C_val, gamma=gamma_val)\n",
    "        \n",
    "        # Fitting Linear Kernel SVM to the Training set\n",
    "        # classifier = SVC(kernel = 'linear', random_state = 0)\n",
    "        \n",
    "        classifier.fit(X_train, Y_train)    \n",
    "        prediction = classifier.predict(X_test)\n",
    "        print(prediction)\n",
    "        loss = np.sum(abs(prediction-Y_test),axis = 0)\n",
    " \n",
    "        print(1-loss/len(Y_test))\n",
    "\n",
    "\n",
    "        vali_data=pd.read_csv('./data/test.csv')\n",
    "        vali_data.fillna(all_data.mean(),inplace = True) \n",
    "        #vali_data=vali_data.drop([\"id\",\"opened_position_qty \" ,\"closed_position_qty\" ,\"transacted_qty\",\"d_open_interest\",\"bid1\",\"bid2\",\"bid3\",\"bid4\",\"bid5\",\"ask1\",\"ask2\",\"ask3\",\"ask4\",\"ask5\"],axis=1)\n",
    "        vali_data[\"bid1sum\"]=vali_data[\"bid1\"]*vali_data[\"bid1vol\"]\n",
    "        vali_data[\"bid2sum\"]=vali_data[\"bid2\"]*vali_data[\"bid2vol\"]\n",
    "        vali_data[\"bid3sum\"]=vali_data[\"bid3\"]*vali_data[\"bid3vol\"]\n",
    "        vali_data[\"bid4sum\"]=vali_data[\"bid4\"]*vali_data[\"bid4vol\"]\n",
    "        vali_data[\"bid5sum\"]=vali_data[\"bid5\"]*vali_data[\"bid5vol\"]\n",
    "        vali_data[\"ask1sum\"]=vali_data[\"ask1\"]*vali_data[\"ask1vol\"]\n",
    "        vali_data[\"ask2sum\"]=vali_data[\"ask2\"]*vali_data[\"ask2vol\"]\n",
    "        vali_data[\"ask3sum\"]=vali_data[\"ask3\"]*vali_data[\"ask3vol\"]\n",
    "        vali_data[\"ask4sum\"]=vali_data[\"ask4\"]*vali_data[\"ask4vol\"]\n",
    "        vali_data[\"ask5sum\"]=vali_data[\"ask5\"]*vali_data[\"ask5vol\"]\n",
    "        \n",
    "        vali_data=vali_data.to_numpy()\n",
    "        vali_data_id=vali_data[:,0]\n",
    "        vali_data=vali_data[:,1:]\n",
    "\n",
    "        vali_predict=classifier.predict(vali_data)      \n",
    "        print(vali_predict[1:30])\n",
    "        \n",
    "        vali_df = pd.DataFrame({\"id\" : vali_data_id, \"Predicted\" : vali_predict})\n",
    "        vali_df['id'] = vali_df['id'].astype(int)\n",
    "        vali_df.to_csv(\"submission2.csv\", index=False)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
